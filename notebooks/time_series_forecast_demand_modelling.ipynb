{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series - Demand - Forecasting\n",
    "https://www.kaggle.com/c/demand-forecasting-kernels-only\n",
    "\n",
    "This competition is provided as a way to explore different time series techniques on a relatively simple and clean dataset.\n",
    "\n",
    "You are given 5 years of store-item sales data, and asked to predict 3 months of sales for 50 different items at 10 different stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import datetime as dt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import itertools\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import statsmodels.api as sm\n",
    "from fbprophet import Prophet\n",
    "from fbprophet.diagnostics import cross_validation\n",
    "from fbprophet.diagnostics import performance_metrics\n",
    "from fbprophet.plot import add_changepoints_to_plot\n",
    "from fbprophet.plot import plot_cross_validation_metric\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set data paths \n",
    "time_series_train_path = Path('../data/time_series_train.csv')\n",
    "time_series_test_path = Path('../data/time_series_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataframe\n",
    "train_df = pd.read_csv(time_series_train_path, parse_dates=['date'])\n",
    "test_df = pd.read_csv(time_series_test_path, parse_dates=['date'], index_col=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  store  item  sales\n",
       "0 2013-01-01      1     1     13\n",
       "1 2013-01-02      1     1     11\n",
       "2 2013-01-03      1     1     14\n",
       "3 2013-01-04      1     1     13\n",
       "4 2013-01-05      1     1     10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  store  item\n",
       "id                        \n",
       "0  2018-01-01      1     1\n",
       "1  2018-01-02      1     1\n",
       "2  2018-01-03      1     1\n",
       "3  2018-01-04      1     1\n",
       "4  2018-01-05      1     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract rolling average and take difference in attempt to create stationary time series\n",
    "def sales_transform(dataf):\n",
    "    \n",
    "    new_df = (dataf\n",
    "              .assign(sales_diff = dataf['sales'].diff(1)\n",
    "                     )\n",
    "             )\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "#Function to split dataframe per store/item combination to model separately\n",
    "def split_data(dataf, store, item):\n",
    "    \n",
    "    splitted_df = dataf[(dataf['store'] == store) & (dataf['item'] == item)]\n",
    "    \n",
    "    return splitted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list with all unique combinations of store and item\n",
    "stores = [s for s in range(1,11)]\n",
    "items = [i for i in range(1,51)]\n",
    "combinations = list(itertools.product(stores, items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create list containing dataframes for all store/item combinations\n",
    "list_train_df_split = []\n",
    "\n",
    "for s, i in combinations:\n",
    "    list_train_df_split.append(train_df.pipe(split_data, store=s, item=i))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1826 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  store  item  sales\n",
       "0    2013-01-01      1     1     13\n",
       "1    2013-01-02      1     1     11\n",
       "2    2013-01-03      1     1     14\n",
       "3    2013-01-04      1     1     13\n",
       "4    2013-01-05      1     1     10\n",
       "...         ...    ...   ...    ...\n",
       "1821 2017-12-27      1     1     14\n",
       "1822 2017-12-28      1     1     19\n",
       "1823 2017-12-29      1     1     15\n",
       "1824 2017-12-30      1     1     27\n",
       "1825 2017-12-31      1     1     23\n",
       "\n",
       "[1826 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First item in dataframe list\n",
    "list_train_df_split[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARIMA (Seasonal ARIMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seasonal Autoregressive Integrated Moving Average, SARIMA or Seasonal ARIMA, is an extension of ARIMA that explicitly supports univariate time series data with a seasonal component.\n",
    "\n",
    "### Trend elements\n",
    "\n",
    "There are three trend elements that require configuration.\n",
    "They are the same as the ARIMA model; specifically:\n",
    "\n",
    "- p: Trend autoregression order: The number of lag observations included in the model, also called the lag order\n",
    "- d: Trend difference order: The number of times that the raw observations are differenced, also called the degree of differencing\n",
    "- q: Trend moving average order: The size of the moving average window, also called the order of moving average\n",
    "\n",
    "### Seasonal Elements\n",
    "There are four seasonal elements that are not part of ARIMA that must be configured; they are:\n",
    "\n",
    "- P: Seasonal autoregressive order.  If the lag m has a positive value then P should be >= 1. Otherwise P should be 0. \n",
    "- D: Seasonal difference order. The rule of thumb for our D parameter is that our series differencing and seasonal differencing should not be greater than 2. If our seasonal pattern is stable overtime then we can set D=1 and set D=0 if the seasonal pattern seems unstable.\n",
    "- Q: Seasonal moving average order.\n",
    "- m: The number of time steps for a single seasonal period. The value m is equal to the lag with the greatest autocorrelation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to run separate SARIMAX models per store/item and output predictions to DataFrame\n",
    "def predict_sarimax(list_dataf):\n",
    "    \n",
    "    #Create empty series to append to\n",
    "    dates = pd.Series(dtype='datetime64[ns]')\n",
    "    stores = pd.Series(dtype='int64')\n",
    "    items = pd.Series(dtype='int64')\n",
    "    actual_sales = pd.Series(dtype='int64')\n",
    "    predicted_sales = pd.Series(dtype='int64')\n",
    "   \n",
    "    #Loop to dataframes and calculate predictions        \n",
    "    for dataframe in list_dataf:\n",
    "\n",
    "        #Append relevant data to main lists per store/item combination\n",
    "        dates = (dates\n",
    "                     .append(dataframe['date'])\n",
    "                     .append(pd.Series(pd.date_range('2018-01-01', '2018-03-31')))\n",
    "                )\n",
    "        stores = (stores\n",
    "                      .append(dataframe['store'])\n",
    "                      .append(pd.Series(np.full(90, dataframe['store'].unique())))\n",
    "                 )\n",
    "        \n",
    "        items = (items\n",
    "                      .append(dataframe['item'])\n",
    "                      .append(pd.Series(np.full(90, dataframe['item'].unique())))\n",
    "                )\n",
    "        \n",
    "         \n",
    "        actual_sales = (actual_sales\n",
    "                            .append(dataframe['sales'])\n",
    "                            .append(pd.Series(np.zeros(90)))\n",
    "                       )\n",
    "                \n",
    "        #Initiate Prophet model, fit and predict\n",
    "        sarimax = sm.tsa.statespace.SARIMAX(dataframe['sales'].values, \n",
    "                                           order=(0,1,1), \n",
    "                                           seasonal_order=(0,1,1,7)\n",
    "                                          )\n",
    "        sarimax_fit = sarimax.fit()\n",
    "\n",
    "        \n",
    "        predicted_sales = predicted_sales.append(pd.Series(sarimax_fit\n",
    "                                                              .get_prediction(start=0, end=1915, dynamic=False)\n",
    "                                                              .predicted_mean\n",
    "                                                          )\n",
    "                                                )\n",
    "        \n",
    "            \n",
    "    #Create new dataframe with predictions\n",
    "    train_df_predictions = pd.DataFrame({'date': dates,\n",
    "                                         'store': stores,\n",
    "                                         'item': items,\n",
    "                                         'actual_sales' : actual_sales.astype(int),\n",
    "                                         'predicted_sales' : (predicted_sales\n",
    "                                                              .values\n",
    "                                                              .astype(int)\n",
    "                                                             )\n",
    "                                         }\n",
    "                                       )\n",
    "    \n",
    "    return train_df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions_sarimax = predict_sarimax(list_train_df_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_predictions_sarimax.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize original versus predicted values for training dataset\n",
    "def plot_original_predicted(dataf, min_date, max_date, store_id, item_id):\n",
    "    \n",
    "    df_selection = dataf[(dataf['date'] > min_date) & (dataf['date'] < max_date) & (dataf['store'] == store_id) & (dataf['item'] == item_id)]\n",
    "        \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=df_selection['date'],\n",
    "                             y=df_selection['actual_sales'],\n",
    "                             mode='lines',\n",
    "                             name='Actual Sales'\n",
    "                            )\n",
    "                 )\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=df_selection['date'],\n",
    "                             y=df_selection['predicted_sales'],\n",
    "                             mode='lines',\n",
    "                             name='Predicted Sales'\n",
    "                            )\n",
    "                 )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_original_predicted(df_predictions_sarimax, \n",
    "                        min_date='2013-08-01', \n",
    "                        max_date='2013-08-31',\n",
    "                        store_id=5,\n",
    "                        item_id=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set actual and predicted sales to calculate SMAPE \n",
    "y_actual_sarimax = df_predictions_sarimax[df_predictions_sarimax['date'] < '2018-01-01']['actual_sales']\n",
    "y_pred_sarimax = df_predictions_sarimax[df_predictions_sarimax['date'] < '2018-01-01']['predicted_sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate smape for original versus predictions\n",
    "def smape(a, f):\n",
    "    return 1/len(a) * np.sum(2 * np.abs(f-a) / (np.abs(a) + np.abs(f))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculate SMAPE\n",
    "smape(y_actual_sarimax, y_pred_sarimax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output predictions for first three months of 2018\n",
    "predictions_sarimax = (df_predictions_sarimax[df_predictions_sarimax['date'] >= '2018-01-01']\n",
    "                           .reset_index()['predicted_sales']\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions_sarimax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions_sarimax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = Path('../data/time_series_SARIMAX_predictions.csv')\n",
    "\n",
    "predictions_sarimax.to_csv(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prophet\n",
    "\n",
    "The procedure makes use of a decomposable time series model with three main model components: trend, seasonality, and holidays.\n",
    "\n",
    "y(t) = g(t) + s(t) + h(t) + e(t)\n",
    "\n",
    "\n",
    "g(t)\n",
    "- trend models non-periodic changes; linear or logistic\n",
    "\n",
    "s(t)\n",
    "- seasonality represents periodic changes; i.e. weekly, monthly, yearly\n",
    "\n",
    "h(t)\n",
    "- ties in effects of holidays; on potentially irregular schedules ≥ 1 day(s)\n",
    "\n",
    "The error term e(t) represents any idiosyncratic changes which are not accommodated by the model; later we will make the parametric assumption that e(t) is normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProphetModel:\n",
    "    \n",
    "    #Initialize with list of dataframes per store/item and other fixed model input\n",
    "    def __init__(self, list_dataf):\n",
    "        \n",
    "        self.list_dataf = list_dataf\n",
    "        #Set holidays to include in model\n",
    "        self.playoffs = pd.DataFrame({'holiday' : 'playoffs',\n",
    "                                      'ds' : pd.to_datetime(['2013-01-12','2013-07-12','2013-12-24', '2014-01-12', \n",
    "                                                             '2014-07-12', '2014-07-19', '2014-07-02','2014-12-24', \n",
    "                                                             '2015-07-11', '2015-12-24', '2016-07-17', '2016-07-24', \n",
    "                                                             '2016-07-07','2016-07-24','2016-12-24', '2017-07-17',\n",
    "                                                             '2017-07-24','2017-07-07','2017-12-24'\n",
    "                                                             ]\n",
    "                                                            ),\n",
    "                                        #Used to identify spillover effect to previous of next days\n",
    "                                        'lower_window' : 0,\n",
    "                                        'upper_window' : 2\n",
    "                                     }\n",
    "                                    )\n",
    "        \n",
    "        self.superbowls = pd.DataFrame({'holiday': 'superbowl',\n",
    "                                        'ds': pd.to_datetime(['2013-01-01','2013-01-21','2013-02-14','2013-02-18',\n",
    "                                                              '2013-05-27','2013-07-04','2013-09-02','2013-10-14',\n",
    "                                                              '2013-11-11','2013-11-28','2013-12-25','2014-01-01',\n",
    "                                                              '2014-01-20','2014-02-14','2014-02-17', '2014-05-26',\n",
    "                                                              '2014-07-04','2014-09-01','2014-10-13','2014-11-11',\n",
    "                                                              '2014-11-27','2014-12-25','2015-01-01','2015-01-19',\n",
    "                                                              '2015-02-14','2015-02-16','2015-05-25','2015-07-03',\n",
    "                                                              '2015-09-07','2015-10-12','2015-11-11','2015-11-26',\n",
    "                                                              '2015-12-25','2016-01-01','2016-01-18','2016-02-14',\n",
    "                                                              '2016-02-15', '2016-05-30','2016-07-04','2016-09-05',\n",
    "                                                              '2016-10-10','2016-11-11','2016-11-24','2016-12-25',\n",
    "                                                              '2017-01-02','2017-01-16','2017-02-14','2017-02-20',\n",
    "                                                              '2017-05-29','2017-07-04','2017-09-04','2017-10-09',\n",
    "                                                              '2017-11-10','2017-11-23','2017-12-25','2018-01-01',\n",
    "                                                              '2018-01-15','2018-02-14','2018-02-19'\n",
    "                                                              ]\n",
    "                                                             ),\n",
    "                                            'lower_window': 0,\n",
    "                                            'upper_window': 3,\n",
    "                                        }\n",
    "                                       )\n",
    "        \n",
    "        self.holidays = pd.concat((self.playoffs, self.superbowls))\n",
    "        \n",
    "        #Determine dates to predict\n",
    "        self.dates_to_predict = (pd.DataFrame({'ds': (self.list_dataf[0]['date']\n",
    "                                                          .append(pd.Series(pd.date_range('2018-01-01', '2018-03-31')))\n",
    "                                                     )\n",
    "\n",
    "                                              }\n",
    "                                             )\n",
    "                                )\n",
    "    \n",
    "    #Run Prophet model for multiple store/item combinations with different parameters and print SMAPE\n",
    "    def predict_single_search(self, store_id, item_id):\n",
    "        \n",
    "        #Set parameter grid to tune model\n",
    "        params = {#'fourier_order_week': [5, 10, 15, 20, 25, 30],\n",
    "                  'fourier_order_year': [5, 10, 15, 20, 25, 30],\n",
    "                  #'prior_scale_week':[2, 4, 6, 8, 10],\n",
    "                  'prior_scale_year':[2, 4, 6, 8, 10]\n",
    "                 }\n",
    "        grid = ParameterGrid(params)\n",
    "        \n",
    "        #Create evaluation dataframe\n",
    "        evaluation_df = pd.DataFrame(columns=['model_parameters', 'MAPE'])\n",
    "        \n",
    "        for dataframe in list_train_df_split:\n",
    "            \n",
    "            if all(dataframe['store'] == store_id) and all(dataframe['item'] == item_id):\n",
    "                \n",
    "                #Create input dataframe for Prophet prediction\n",
    "                input_df_prophet = pd.DataFrame({'ds': dataframe['date'],\n",
    "                                                 'y': dataframe['sales']\n",
    "                                                }\n",
    "                                               )     \n",
    "                \n",
    "                #Use parameter grid to test different models\n",
    "                for p in grid:\n",
    "                \n",
    "                    #Initiate Prophet model\n",
    "                    ph_single = Prophet(daily_seasonality=False,\n",
    "                                        weekly_seasonality=False,\n",
    "                                        yearly_seasonality=False\n",
    "                                       )\n",
    "\n",
    "                    (ph_single\n",
    "                         .add_seasonality(name='weekly', period=7, \n",
    "                                          fourier_order=10, prior_scale=0.5)\n",
    "                         .add_seasonality(name='yearly', period=365, \n",
    "                                          fourier_order=p['fourier_order_year'], prior_scale=p['prior_scale_year'])\n",
    "                    )\n",
    "\n",
    "                    #Fit Prophet model\n",
    "                    ph_single.fit(input_df_prophet)  \n",
    "                                                                 \n",
    "                    #Make forecast\n",
    "                    ph_single_forecast = ph_single.predict(self.dates_to_predict)\n",
    "                                                                 \n",
    "                    predictions = ph_single_forecast[ph_single_forecast['ds'] < '2018-01-01']['yhat']\n",
    "                                                                 \n",
    "                    #Calculate MAPE for different parameters\n",
    "                    mape = mean_absolute_error(dataframe['sales'], predictions)                    \n",
    "                    \n",
    "                    evaluation_df = evaluation_df.append({'model_parameters': p,\n",
    "                                                          'MAPE': mape\n",
    "                                                          },\n",
    "                                                           ignore_index=True\n",
    "                                                        )\n",
    "                    \n",
    "        #Print model parameters with smallest MAPE\n",
    "        min_mape_idx = evaluation_df['MAPE'].idxmin()\n",
    "        print(f\"{evaluation_df.loc[min_mape_idx]['model_parameters']}: {evaluation_df.loc[min_mape_idx]['MAPE']}\")                                       \n",
    "    \n",
    "    #Predict using best model and plot forecast for single store/item combination\n",
    "    def predict_single(self, store_id, item_id):\n",
    "        \n",
    "        for dataframe in self.list_dataf:\n",
    "            \n",
    "            if all(dataframe['store'] == store_id) and all(dataframe['item'] == item_id):\n",
    "                \n",
    "                #Create input dataframe for Prophet prediction\n",
    "                input_df_prophet = pd.DataFrame({'ds': dataframe['date'],\n",
    "                                                 'y': dataframe['sales']\n",
    "                                                }\n",
    "                                               )\n",
    "                \n",
    "                ph_single = Prophet(n_changepoints=200,\n",
    "                                    changepoint_prior_scale=0.5,\n",
    "                                    seasonality_mode='multiplicative',\n",
    "                                    daily_seasonality=False,\n",
    "                                    weekly_seasonality=False,\n",
    "                                    yearly_seasonality=False\n",
    "                                    )\n",
    "\n",
    "                (ph_single\n",
    "                    .add_seasonality(name='weekly', period=7, \n",
    "                                     fourier_order=17, prior_scale=0.6)\n",
    "                    .add_seasonality(name='yearly', period=365.5, fourier_order=20, prior_scale= 0.8)\n",
    "                    .add_seasonality(name='daily', period=1, fourier_order=17)\n",
    "                )\n",
    "\n",
    "                #Fit Prophet model\n",
    "                ph_single.fit(input_df_prophet)  \n",
    "                                                                 \n",
    "                #Make forecast\n",
    "                ph_single_forecast = ph_single.predict(self.dates_to_predict)\n",
    "        \n",
    "                #Plot forecast\n",
    "                fig = ph_single.plot(ph_single_forecast, xlabel='Date', ylabel='Sales')\n",
    "                fig_changepoints = add_changepoints_to_plot(fig.gca(), ph_single, ph_single_forecast)\n",
    "\n",
    "                #Plot components\n",
    "                ph_single.plot_components(ph_single_forecast)                \n",
    "                                                               \n",
    "    #Run separate Prophet models per store/item and output predictions to DataFrame\n",
    "    def predict_all(self):\n",
    "\n",
    "        #Create empty series to append to\n",
    "        self.dates = pd.Series(dtype='datetime64[ns]')\n",
    "        self.stores = pd.Series(dtype='int64')\n",
    "        self.items = pd.Series(dtype='int64')\n",
    "        self.actual_sales = pd.Series(dtype='int64')\n",
    "        self.predicted_sales = pd.Series(dtype='int64')\n",
    "\n",
    "        #Loop to dataframes and calculate predictions        \n",
    "        for dataframe in self.list_dataf:\n",
    "\n",
    "            #Append relevant data to main series per store/item combination\n",
    "            self.dates = (self.dates\n",
    "                              .append(dataframe['date'])\n",
    "                              .append(pd.Series(pd.date_range('2018-01-01', '2018-03-31')))\n",
    "                         )\n",
    "\n",
    "            self.stores = (self.stores\n",
    "                               .append(dataframe['store'])\n",
    "                               .append(pd.Series(np.full(90, dataframe['store'].unique())))\n",
    "                          )\n",
    "\n",
    "            self.items = (self.items\n",
    "                               .append(dataframe['item'])\n",
    "                               .append(pd.Series(np.full(90, dataframe['item'].unique())))\n",
    "                         )\n",
    "\n",
    "\n",
    "            self.actual_sales = (self.actual_sales\n",
    "                                     .append(dataframe['sales'])\n",
    "                                     .append(pd.Series(np.zeros(90)))\n",
    "                                )\n",
    "\n",
    "            #Create input dataframe for Prophet prediction\n",
    "            input_df_prophet = pd.DataFrame({'ds': dataframe['date'],\n",
    "                                             'y': dataframe['sales']\n",
    "                                            }\n",
    "                                           )\n",
    "                \n",
    "            ph = Prophet(daily_seasonality=False,\n",
    "                         weekly_seasonality=True,\n",
    "                         yearly_seasonality=True\n",
    "                        )\n",
    "\n",
    "            ph.fit(input_df_prophet)\n",
    "\n",
    "            forecast_prophet = ph.predict(self.dates_to_predict)\n",
    "            \n",
    "            #Append predictions to dataframe \n",
    "            self.predicted_sales = self.predicted_sales.append(forecast_prophet['yhat'])\n",
    "\n",
    "        #Create new dataframe with predictions\n",
    "        self.train_df_predictions = pd.DataFrame({'date': self.dates,\n",
    "                                                  'store': self.stores,\n",
    "                                                  'item': self.items,\n",
    "                                                  'actual_sales' : self.actual_sales.astype(int),\n",
    "                                                  'predicted_sales' : (self.predicted_sales\n",
    "                                                                           .values\n",
    "                                                                           .astype(int)\n",
    "                                                                      )\n",
    "                                                 }\n",
    "                                                )\n",
    "\n",
    "        return self.train_df_predictions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Prophet for multiple single item/store combinations, trying different parameters and calculate MAPE \n",
    "for store, item in list(itertools.product([1,2,3,4,5], [1,2,3,4,5])):\n",
    "    \n",
    "    ProphetModel(list_train_df_split).predict_single_search(store_id=store, item_id=item)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Prophet for single item/store combinations and plot forecast\n",
    "(ProphetModel(list_train_df_split)\n",
    "     .predict_single(store_id=1, item_id=5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Predict in rounds for full dataset\n",
    "df_predictions_prophet = (ProphetModel(list_train_df_split)\n",
    "                              .predict_all()\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "      <th>actual_sales</th>\n",
       "      <th>predicted_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  store  item  actual_sales  predicted_sales\n",
       "0 2013-01-01      1     1            13                8\n",
       "1 2013-01-02      1     1            11                9\n",
       "2 2013-01-03      1     1            14                9\n",
       "3 2013-01-04      1     1            13               11\n",
       "4 2013-01-05      1     1            10               13"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions_prophet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set actual and predicted sales to calculate SMAPE \n",
    "y_actual_prophet = df_predictions_prophet[df_predictions_prophet['date'] < '2018-01-01']['actual_sales']\n",
    "y_pred_prophet = df_predictions_prophet[df_predictions_prophet['date'] < '2018-01-01']['predicted_sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.886024096385542"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate MAPE\n",
    "mean_absolute_error(y_actual_prophet, y_pred_prophet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output predictions for first three months of 2018\n",
    "predictions_prophet = (df_predictions_prophet[df_predictions_prophet['date'] >= '2018-01-01']\n",
    "                           .reset_index()['predicted_sales']\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_prophet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        12\n",
       "1        15\n",
       "2        16\n",
       "3        16\n",
       "4        18\n",
       "         ..\n",
       "44995    75\n",
       "44996    76\n",
       "44997    81\n",
       "44998    86\n",
       "44999    91\n",
       "Name: predicted_sales, Length: 45000, dtype: int32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = Path('../data/time_series_PROPHET_predictions.csv')\n",
    "\n",
    "predictions_prophet.to_csv(save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
